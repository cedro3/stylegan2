{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Edit_new_image",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/stylegan2/blob/master/Edit_new_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWtBaGbmLubM"
      },
      "source": [
        "# Edit_new_image\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bAVpVONtwUw"
      },
      "source": [
        "# 1.セットアップ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doZxGZkZiFkR"
      },
      "source": [
        "githubからコードを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyI-JqcYsmbT"
      },
      "source": [
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.2.4\n",
        "!git clone https://github.com/cedro3/stylegan2.git\n",
        "%cd stylegan2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFJNpgfw79f4"
      },
      "source": [
        "必要な関数を定義します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwU_4rN5SgZR"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "import PIL.Image\n",
        "import sys\n",
        "import bz2\n",
        "from keras.utils import get_file\n",
        "import dlib\n",
        "import argparse\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import projector\n",
        "import pretrained_networks\n",
        "from training import dataset\n",
        "from training import misc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "\n",
        "# -------------- 潜在変数によって生成する顔画像の表示 -------------\n",
        "def display(vec_syn):\n",
        "  \n",
        "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'  \n",
        "    \n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = True \n",
        "    Gs_syn_kwargs.truncation_psi = 0.5\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 24))   \n",
        "    for i in trange(len(vec_syn)):\n",
        "        vec = vec_syn[i].reshape(1,18,512)\n",
        "        image =  Gs.components.synthesis.run(vec, **Gs_syn_kwargs)        \n",
        "        PIL.Image.fromarray(image[0], 'RGB')   \n",
        "        ax = fig.add_subplot(10, 5, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(image[0])\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# ------------- 潜在変数の指定インデックス間のアニメーション -------\n",
        "def generate_gif(vec_syn, idx):\n",
        "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'  \n",
        "    \n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = True \n",
        "    Gs_syn_kwargs.truncation_psi = 0.5\n",
        "\n",
        "    image_gif_256 = []\n",
        "    os.makedirs('my/gif', exist_ok=True)\n",
        "    for j in trange(len(idx)-1):\n",
        "        for i in range(40):\n",
        "            vec = vec_syn[idx[j]]+(vec_syn[idx[j+1]]-vec_syn[idx[j]])*i/39\n",
        "            vec = vec.reshape(1, 18, 512)\n",
        "            images =  Gs.components.synthesis.run(vec, **Gs_syn_kwargs) \n",
        "            image_one = PIL.Image.fromarray(images[0], 'RGB')\n",
        "            image_gif_256.append(image_one.resize((256,256))) \n",
        "\n",
        "    print('making_gif...')\n",
        "    image_gif_256[0].save('./my/gif/anime_256.gif', save_all=True, append_images=image_gif_256[1:],\n",
        "                      duration=100, loop=0) \n",
        "\n",
        "# --------- Style Mixing の実行 -----------\n",
        "def style_mixing(vec_syn, col_styles, truncation_psi):  \n",
        "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n",
        "    row_seeds = [1, 2, 3]\n",
        "    col_seeds = [4, 5, 6]\n",
        "    col_styles = col_styles\n",
        "    truncation_psi = truncation_psi\n",
        "    minibatch_size = 4\n",
        "\n",
        "    # Loading networks \n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = False\n",
        "    Gs_syn_kwargs.minibatch_size = minibatch_size\n",
        "\n",
        "    # Generating W vectors\n",
        "    all_seeds = list(row_seeds + col_seeds)   \n",
        "    all_w = vec_syn[:6]\n",
        "    w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))} # [layer, component]\n",
        "\n",
        "    print('Generating images...') \n",
        "    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs) # [minibatch, height, width, channel]\n",
        "    image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n",
        "\n",
        "    print('Generating style-mixed images...')\n",
        "    for row_seed in row_seeds:\n",
        "        for col_seed in col_seeds:\n",
        "            w = w_dict[row_seed].copy()\n",
        "            w[col_styles] = w[col_styles] + (w_dict[col_seed][col_styles]-w[col_styles])*truncation_psi\n",
        "            image = Gs.components.synthesis.run(w[np.newaxis], **Gs_syn_kwargs)[0]\n",
        "            image_dict[(row_seed, col_seed)] = image\n",
        "\n",
        "    print('Saving images...')\n",
        "    os.makedirs('my/stylemix_images', exist_ok=True)\n",
        "    for (row_seed, col_seed), image in image_dict.items():\n",
        "        PIL.Image.fromarray(image, 'RGB').save('./my/stylemix_images/'+str(row_seed)+'-'+str(col_seed)+'.png')\n",
        "\n",
        "    print('Saving image grid...')\n",
        "    _N, _C, H, W = Gs.output_shape\n",
        "    canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n",
        "\n",
        "    r, c = 4, 4  # スクリーン設定（4行×4列）\n",
        "    fig, axs = plt.subplots(r, c, figsize=(10,10), subplot_kw=({'xticks':(),'yticks':()}))\n",
        "\n",
        "    for row_idx, row_seed in enumerate([None] + row_seeds):\n",
        "        for col_idx, col_seed in enumerate([None] + col_seeds):\n",
        "            if row_seed is None and col_seed is None:\n",
        "                continue\n",
        "            key = (row_seed, col_seed)\n",
        "            if row_seed is None:\n",
        "                key = (col_seed, col_seed)\n",
        "            if col_seed is None:\n",
        "                key = (row_seed, row_seed)\n",
        "            canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx)) \n",
        "\n",
        "            # スクリーンに画像配置            \n",
        "            image_plt = np.array(image_dict[key])\n",
        "            axs[row_idx, col_idx].imshow(image_plt)\n",
        "            if row_seed is None:\n",
        "                x, y = col_seed, col_seed\n",
        "            elif col_seed is None:\n",
        "                x, y = row_seed, row_seed\n",
        "            else:\n",
        "                x, y = row_seed, col_seed\n",
        "            axs[row_idx, col_idx].set_xlabel(str(x)+'-'+str(y))\n",
        "\n",
        "    canvas.save('./my/stylemix_images/grid.png') \n",
        "\n",
        "    # スクリーン表示\n",
        "    black = np.zeros((1024,1024,3))  # 黒画像作成\n",
        "    axs[0,0].imshow(black)\n",
        "    axs[0,0].axis('off')\n",
        "    plt.show()\n",
        "    plt.close()   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_D7kUH6gyPB"
      },
      "source": [
        "#2.今回準備した潜在変数を見てみる\n",
        "sampleデータをロードします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQfhcVIeelrQ"
      },
      "source": [
        "vec_direction = np.load('sample/vectors/vec_direction.npy')\n",
        "vec_smile = np.load('sample/vectors/vec_smile.npy')\n",
        "vec_glass = np.load('sample/vectors/vec_glass.npy')\n",
        "vec_young = np.load('sample/vectors/vec_young.npy')\n",
        "vec_old = np.load('sample/vectors/vec_old.npy')\n",
        "vec_man = np.load('sample/vectors/vec_man.npy')\n",
        "vec_all = np.load('sample/vectors/vec_all.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spHJAJVkeEZG"
      },
      "source": [
        "潜在変数vec_allによって生成される画像の一覧を表示します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYoKKRqtg6iB"
      },
      "source": [
        "display(vec_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpc-VVuAeZx8"
      },
      "source": [
        "モーフィングをやってみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuo2nFSSgiCp"
      },
      "source": [
        "from IPython.display import Image\n",
        "generate_gif(vec_all, [9, 11, 21, 17])\n",
        "Image('./my/gif/anime_256.gif', format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POm2EngYhGAl"
      },
      "source": [
        "#3.Style_Mixing\n",
        "指定された潜在変数wをRow_picとCol_picで入れ替えます。\\\n",
        "第１引数：ベクトル名\\\n",
        "第２引数：Wの指定（リスト形式）\\\n",
        "第３引数：Col_picのWに掛け算する係数(0〜1はRow_colとの混合割合)\\\n",
        "＊生成した画像は、my/stylemix_images に上書き保存します\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60vVvvTNfrUI"
      },
      "source": [
        "# Face_direction\n",
        "style_mixing(vec_direction, [0,1], 1.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2OvM47BhYKS"
      },
      "source": [
        "# Smile\n",
        "style_mixing(vec_smile, [4,5], 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t9jN22ZhOP-"
      },
      "source": [
        "# Glasses\n",
        "style_mixing(vec_glass, [0,1,2], 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTMQYr2MXQwm"
      },
      "source": [
        "# UnGlasses\n",
        "vec_glass1 = np.vstack((vec_glass[3:],vec_glass[:3]))\n",
        "style_mixing(vec_glass1, [0,1,2], 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWuvM5yuhb3r"
      },
      "source": [
        "# Young\n",
        "style_mixing(vec_young, [4,5,6,7], 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3eoleBhhcmx"
      },
      "source": [
        "# Old\n",
        "style_mixing(vec_old, [4,5,6,7], 0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGRpoGzRhgMX"
      },
      "source": [
        "# Man\n",
        "style_mixing(vec_man, [4,5,6,7], 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
